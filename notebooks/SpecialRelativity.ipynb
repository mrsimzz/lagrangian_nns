{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax import jit\n",
    "from jax.experimental.ode import odeint\n",
    "from functools import partial\n",
    "\n",
    "from jax.example_libraries import optimizers\n",
    "\n",
    "\n",
    "from lnn.hyperopt.HyperparameterSearch import extended_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagrangian_eom(lagrangian, state, conditionals, t=None):\n",
    "    q, q_t = jnp.split(state, 2)\n",
    "    q = q / 10.0  # Normalize\n",
    "    conditionals = conditionals / 10.0\n",
    "    q_t = q_t\n",
    "    q_tt = jnp.linalg.pinv(jax.hessian(lagrangian, 1)(q, q_t, conditionals)) @ (\n",
    "        jax.grad(lagrangian, 0)(q, q_t, conditionals)\n",
    "        - jax.jacobian(jax.jacobian(lagrangian, 1), 0)(q, q_t, conditionals) @ q_t\n",
    "    )\n",
    "    return jnp.concatenate([q_t, q_tt])\n",
    "\n",
    "\n",
    "# replace the lagrangian with a parameteric model\n",
    "def learned_dynamics(params, nn_forward_fn):\n",
    "    @jit\n",
    "    def dynamics(q, q_t, conditionals):\n",
    "        #     assert q.shape == (2,)\n",
    "        state = jnp.concatenate([q, q_t, conditionals])\n",
    "        return jnp.squeeze(nn_forward_fn(params, state), axis=-1)\n",
    "\n",
    "    return dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectView(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def qdotdot(q, q_t, conditionals):\n",
    "    g = conditionals\n",
    "\n",
    "    q_tt = g * (1 - q_t**2) ** (5.0 / 2) / (1 + 2 * q_t**2)\n",
    "\n",
    "    return q_t, q_tt\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def ofunc(y, t=None):\n",
    "    q = y[::3]\n",
    "    q_t = y[1::3]\n",
    "    g = y[2::3]\n",
    "\n",
    "    q_t, q_tt = qdotdot(q, q_t, g)\n",
    "    return jnp.stack([q_t, q_tt, jnp.zeros_like(g)]).T.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(jnp.tanh(jax.random.uniform(jax.random.PRNGKey(1), (1000,)) * 10 - 5) * 0.99999).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((jnp.tanh(jax.random.normal(jax.random.PRNGKey(1), (100,)) * 2) * 0.99999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnums=(1, 2), backend=\"cpu\")\n",
    "def gen_data(seed, batch, num):\n",
    "    rng = jax.random.PRNGKey(seed)\n",
    "    q0 = jax.random.uniform(rng, (batch,), minval=-10, maxval=10)\n",
    "    qt0 = jax.random.uniform(rng + 1, (batch,), minval=-0.99, maxval=0.99)\n",
    "    g = jax.random.normal(rng + 2, (batch,)) * 10\n",
    "\n",
    "    y0 = jnp.stack([q0, qt0, g]).T.ravel()\n",
    "\n",
    "    yt = odeint(\n",
    "        ofunc,\n",
    "        y0,\n",
    "        jnp.linspace(0, 1, num=num),\n",
    "    )\n",
    "\n",
    "    qall = yt[:, ::3]\n",
    "    qtall = yt[:, 1::3]\n",
    "    gall = yt[:, 2::3]\n",
    "\n",
    "    return (\n",
    "        jnp.stack([qall, qtall]).reshape(2, -1).T,\n",
    "        gall.reshape(1, -1).T,\n",
    "        qdotdot(qall, qtall, gall)[1].reshape(1, -1).T,\n",
    "    )\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(1,))\n",
    "def gen_data_batch(seed, batch):\n",
    "    rng = jax.random.PRNGKey(seed)\n",
    "    q0 = jax.random.uniform(rng, (batch,), minval=-10, maxval=10)\n",
    "    qt0 = (\n",
    "        jnp.tanh(jax.random.normal(jax.random.PRNGKey(1), (batch,)) * 2) * 0.99999\n",
    "    )  # jax.random.uniform(rng+1, (batch,), minval=-1, maxval=1)\n",
    "    g = jax.random.normal(rng + 2, (batch,)) * 10\n",
    "\n",
    "    return (\n",
    "        jnp.stack([q0, qt0]).reshape(2, -1).T,\n",
    "        g.reshape(1, -1).T,\n",
    "        qdotdot(q0, qt0, g)[1].reshape(1, -1).T,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"qt\",\n",
    "    gen_data_batch(0, 128)[0][:5, 1],\n",
    "    \"g\",\n",
    "    gen_data_batch(0, 128)[1][:5, 0],\n",
    "    \"qtt\",\n",
    "    gen_data_batch(0, 128)[2][:5, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qdotdot(jnp.array([0]), jnp.array([0.9]), jnp.array([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.29830917716026306 {'act': [4],\n",
    "# 'batch_size': [27.0], 'dt': [0.09609870774790222],\n",
    "# 'hidden_dim': [596.0], 'l2reg': [0.24927677946969878],\n",
    "# 'layers': [4.0], 'lr': [0.005516656601005163],\n",
    "# 'lr2': [1.897157209816416e-05], 'n_updates': [4.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded = pkl.load(open('./params_for_loss_0.29429444670677185_nupdates=1.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ObjectView(\n",
    "    {\n",
    "        \"dataset_size\": 200,\n",
    "        \"fps\": 10,\n",
    "        \"samples\": 100,\n",
    "        \"num_epochs\": 80000,\n",
    "        \"seed\": 0,\n",
    "        \"loss\": \"l1\",\n",
    "        \"act\": \"softplus\",\n",
    "        \"hidden_dim\": 500,\n",
    "        \"output_dim\": 1,\n",
    "        \"layers\": 4,\n",
    "        \"n_updates\": 1,\n",
    "        \"lr\": 0.001,\n",
    "        \"lr2\": 2e-05,\n",
    "        \"dt\": 0.1,\n",
    "        \"model\": \"gln\",\n",
    "        \"batch_size\": 68,\n",
    "        \"l2reg\": 5.7e-07,\n",
    "    }\n",
    ")\n",
    "# args = loaded['args']\n",
    "rng = jax.random.PRNGKey(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = None\n",
    "best_loss = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_random_params, nn_forward_fn = extended_mlp(args)\n",
    "rng = jax.random.PRNGKey(0)\n",
    "_, init_params = init_random_params(rng, (-1, 3))\n",
    "rng += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the output. Now, let's train it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: add identity before inverse:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_small_loss = np.inf\n",
    "iteration = 0\n",
    "total_epochs = 100\n",
    "minibatch_per = 3000\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "lr = 1e-3  # 1e-3\n",
    "\n",
    "final_div_factor = 1e4\n",
    "\n",
    "\n",
    "# OneCycleLR:\n",
    "@jax.jit\n",
    "def OneCycleLR(pct):\n",
    "    # Rush it:\n",
    "    start = 0.3  # 0.2\n",
    "    pct = pct * (1 - start) + start\n",
    "    high, low = lr, lr / final_div_factor\n",
    "\n",
    "    scale = 1.0 - (jnp.cos(2 * jnp.pi * pct) + 1) / 2\n",
    "\n",
    "    return low + (high - low) * scale\n",
    "\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.adam(OneCycleLR)\n",
    "from lnn import custom_init\n",
    "\n",
    "init_params = custom_init(init_params, seed=0)\n",
    "opt_state = opt_init(init_params)\n",
    "# opt_state = opt_init(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(OneCycleLR(jnp.linspace(0, 1, num=200)))\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"lr schedule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss(params, cstate, cconditionals, ctarget):\n",
    "    runner = jax.vmap(\n",
    "        partial(lagrangian_eom, learned_dynamics(params, nn_forward_fn)), (0, 0), 0\n",
    "    )\n",
    "    preds = runner(cstate, cconditionals)[:, [1]]\n",
    "\n",
    "    error = jnp.abs(preds - ctarget)\n",
    "    # Weight additionally by proximity to c!\n",
    "    error_weights = 1 + 1 / jnp.sqrt(1.0 - cstate[:, [1]] ** 2)\n",
    "\n",
    "    return jnp.sum(error * error_weights) * len(preds) / jnp.sum(error_weights)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update_derivative(i, opt_state, cstate, cconditionals, ctarget):\n",
    "    params = get_params(opt_state)\n",
    "    param_update = jax.grad(lambda *args: loss(*args) / len(cstate), 0)(\n",
    "        params, cstate, cconditionals, ctarget\n",
    "    )\n",
    "    params = get_params(opt_state)\n",
    "    return opt_update(i, param_update, opt_state), params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstate, cconditionals, ctarget = gen_data_batch(epoch, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(get_params(opt_state), cstate, cconditionals, ctarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_derivative(0, opt_state, cstate, cconditionals, ctarget);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data_batch(0, 128)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cconditionals[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstate[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctarget[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = np.inf\n",
    "best_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy as copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(epoch, total_epochs)):\n",
    "    epoch_loss = 0.0\n",
    "    num_samples = 0\n",
    "    batch = 512\n",
    "    ocstate, occonditionals, octarget = gen_data_batch(epoch, minibatch_per * batch)\n",
    "    for minibatch in range(minibatch_per):\n",
    "        fraction = (epoch + minibatch / minibatch_per) / total_epochs\n",
    "        s = np.s_[minibatch * batch : (minibatch + 1) * batch]\n",
    "\n",
    "        cstate, cconditionals, ctarget = ocstate[s], occonditionals[s], octarget[s]\n",
    "        opt_state, params = update_derivative(\n",
    "            fraction, opt_state, cstate, cconditionals, ctarget\n",
    "        )\n",
    "        rng += 10\n",
    "\n",
    "        cur_loss = loss(params, cstate, cconditionals, ctarget)\n",
    "\n",
    "        epoch_loss += cur_loss\n",
    "        num_samples += len(cstate)\n",
    "    closs = epoch_loss / num_samples\n",
    "    print(\"epoch={} lr={} loss={}\".format(epoch, OneCycleLR(fraction), closs))\n",
    "    if closs < best_loss:\n",
    "        best_loss = closs\n",
    "        best_params = [\n",
    "            [copy(jax.device_get(l2)) for l2 in l1] if len(l1) > 0 else ()\n",
    "            for l1 in params\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl.dump({'params': best_params, 'description': 'q and g are divided by 10. hidden=500. act=Softplus'},\n",
    "#          open('best_sr_params_v2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = pkl.load(open(\"best_sr_params_v2.pkl\", \"rb\"))[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_state = opt_init(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstate, cconditionals, ctarget = gen_data(0, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cstate[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_params(opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"font\", family=\"serif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4 * 1, 4 * 1), sharex=True, sharey=True)\n",
    "ax_idx = [(i, j) for i in range(1) for j in range(1)]\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "    ci = ax_idx[i]\n",
    "\n",
    "    cstate, cconditionals, ctarget = gen_data((i + 4) * (i + 1), 1, 50)\n",
    "\n",
    "    runner = jax.jit(\n",
    "        jax.vmap(\n",
    "            partial(lagrangian_eom, learned_dynamics(params, nn_forward_fn)), (0, 0), 0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    @jax.jit\n",
    "    def odefunc_learned(y, t):\n",
    "        return jnp.concatenate((runner(y[None, :2], y[None, [2]])[0], jnp.zeros(1)))\n",
    "\n",
    "    yt_learned = odeint(\n",
    "        odefunc_learned,\n",
    "        jnp.concatenate([cstate[0], cconditionals[0]]),\n",
    "        np.linspace(0, 1, 50),\n",
    "    )\n",
    "\n",
    "    cax = ax  # [ci[0], ci[1]]\n",
    "    cax.plot(cstate[:, 1], label=\"Truth\")\n",
    "    cax.plot(yt_learned[:, 1], label=\"Learned\")\n",
    "    cax.legend()\n",
    "    if ci[1] == 0:\n",
    "        cax.set_ylabel(\"Velocity of particle/Speed of light\")\n",
    "    if ci[0] == 0:\n",
    "        cax.set_xlabel(\"Time\")\n",
    "\n",
    "    cax.set_ylim(-1, 1)\n",
    "\n",
    "plt.title(\"Lagrangian NN - Special Relativity\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sr_lnn.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "main2",
   "language": "python",
   "name": "main2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
