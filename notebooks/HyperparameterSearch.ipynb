{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "from jax.example_libraries import optimizers\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../experiment_dblpend/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../hyperopt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HyperparameterSearch import extended_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectView(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_trajectory_analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from physics import analytical_fn\n",
    "\n",
    "vfnc = jax.jit(jax.vmap(analytical_fn))\n",
    "vget = partial(jax.jit, backend=\"cpu\")(\n",
    "    jax.vmap(\n",
    "        partial(\n",
    "            get_trajectory_analytic,\n",
    "        ),\n",
    "        (0, None),\n",
    "        0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.29830917716026306 {'act': [4],\n",
    "# 'batch_size': [27.0], 'dt': [0.09609870774790222],\n",
    "# 'hidden_dim': [596.0], 'l2reg': [0.24927677946969878],\n",
    "# 'layers': [4.0], 'lr': [0.005516656601005163],\n",
    "# 'lr2': [1.897157209816416e-05], 'n_updates': [4.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ObjectView(\n",
    "    dict(\n",
    "        dataset_size=200,\n",
    "        fps=10,\n",
    "        samples=100,\n",
    "        num_epochs=80000,\n",
    "        seed=0,\n",
    "        loss=\"l1\",\n",
    "        act=\"softplus\",\n",
    "        hidden_dim=500,\n",
    "        output_dim=1,\n",
    "        layers=3,\n",
    "        n_updates=1,  # 6,#4,\n",
    "        lr=1e-3,  # 5.5e-3,\n",
    "        lr2=2e-5,\n",
    "        dt=0.1,\n",
    "        model=\"gln\",\n",
    "        batch_size=68,\n",
    "        l2reg=5.7e-7,\n",
    "    )\n",
    ")\n",
    "rng = jax.random.PRNGKey(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HyperparameterSearch import new_get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = new_get_dataset(\n",
    "    rng + 2,\n",
    "    t_span=[0, args.dataset_size],\n",
    "    fps=args.fps,\n",
    "    samples=args.samples,\n",
    "    test_split=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = None\n",
    "best_loss = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HyperparameterSearch import make_loss, train\n",
    "\n",
    "loss = make_loss(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optimizers.adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_random_params, nn_forward_fn = extended_mlp(args)\n",
    "_, init_params = init_random_params(rng + 1, (-1, 4))\n",
    "import HyperparameterSearch\n",
    "\n",
    "HyperparameterSearch.nn_forward_fn = nn_forward_fn\n",
    "rng += 1\n",
    "model = (nn_forward_fn, init_params)\n",
    "opt_init, opt_update, get_params = opti(\n",
    "    3e-4\n",
    ")  ##lambda i: jnp.select([i<10000, i>= 10000], [args.lr, args.lr2]))\n",
    "opt_state = opt_init(init_params)\n",
    "from jax.tree_util import tree_flatten\n",
    "from copy import deepcopy as copy\n",
    "\n",
    "train(args, model, data, rng)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update_derivative(\n",
    "    i, opt_state, batch, l2reg, params\n",
    "):  # iteration+offset, opt_state, batch, args.l2reg\n",
    "    param_update = jax.grad(loss, 0)(params, batch, l2reg)\n",
    "    new_state = opt_update(i, param_update, opt_state)\n",
    "    leaves, _ = tree_flatten(get_params(new_state))\n",
    "    infinities = sum((~jnp.isfinite(param)).sum() for param in leaves)\n",
    "\n",
    "    def true_fun(x):\n",
    "        # No introducing NaNs.\n",
    "        return new_state, params\n",
    "\n",
    "    def false_fun(x):\n",
    "        # No introducing NaNs.\n",
    "        return opt_state, params\n",
    "\n",
    "    return jax.lax.cond(infinities == 0, 0, true_fun, 0, false_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nn_forward_fn, init_params) = model\n",
    "data = {k: jax.device_put(v) for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_params(params):\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    all_new_params = []\n",
    "    for i in range(len(params)):\n",
    "        new_params = []\n",
    "        for j in range(len(params[i])):\n",
    "            p = params[i][j]\n",
    "            n_in = p.shape[0]\n",
    "            n_out = 0 if len(p.shape) == 1 else p.shape[1]\n",
    "\n",
    "            scaling = np.sqrt(6) / np.sqrt(n_in + n_out)\n",
    "            new_p = jax.random.normal(rng, p.shape)\n",
    "\n",
    "            if n_out > 0:\n",
    "                if n_in >= n_out:\n",
    "                    new_p = jnp.linalg.qr(new_p)[0]\n",
    "                else:\n",
    "                    new_p = jnp.linalg.qr(new_p.T)[0].T\n",
    "\n",
    "            new_p *= scaling\n",
    "            rng += 1\n",
    "\n",
    "            new_params.append(new_p)\n",
    "        new_params = tuple(new_params)\n",
    "        all_new_params.append(new_params)\n",
    "    return all_new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _i in range(10000):\n",
    "    print(\"Running\", _i)\n",
    "    print(\"Cur best\", str(best_loss))\n",
    "\n",
    "    best_small_loss = np.inf\n",
    "    iteration = 0\n",
    "    train_losses, test_losses = [], []\n",
    "\n",
    "    lr = args.lr\n",
    "    _, init_params = init_random_params(rng + 1, (-1, 4))\n",
    "    rng += 1\n",
    "    opt_init, opt_update, get_params = opti(lr)\n",
    "    init_params = make_new_params(init_params)\n",
    "    opt_state = opt_init(init_params)\n",
    "    bad_iterations = 0\n",
    "    offset = 0\n",
    "\n",
    "    while iteration < 20000:\n",
    "        iteration += 1\n",
    "        rand_idx = jax.random.randint(rng, (args.batch_size,), 0, len(data[\"x\"]))\n",
    "        rng += 1\n",
    "\n",
    "        batch = (data[\"x\"][rand_idx], data[\"dx\"][rand_idx])\n",
    "\n",
    "        # Compute derivative at halfway point:\n",
    "        half_state, params = update_derivative(\n",
    "            iteration + offset, opt_state, batch, args.l2reg, get_params(opt_state)\n",
    "        )\n",
    "        half_params = get_params(half_state)\n",
    "        opt_state, _ = update_derivative(\n",
    "            iteration + offset, opt_state, batch, args.l2reg, half_params\n",
    "        )\n",
    "        params = get_params(opt_state)\n",
    "\n",
    "        del half_params\n",
    "        del half_state\n",
    "\n",
    "        small_loss = loss(params, batch, 0.0)\n",
    "\n",
    "        new_small_loss = False\n",
    "        if small_loss < best_small_loss:\n",
    "            best_small_loss = small_loss\n",
    "            new_small_loss = True\n",
    "\n",
    "        if (\n",
    "            jnp.isnan(small_loss).sum()\n",
    "            or new_small_loss\n",
    "            or (iteration % 500 == 0)\n",
    "            or (iteration < 1000 and iteration % 100 == 0)\n",
    "        ):\n",
    "            params = get_params(opt_state)\n",
    "            train_loss = loss(params, (data[\"x\"], data[\"dx\"]), 0.0) / len(data[\"x\"])\n",
    "            train_losses.append(train_loss)\n",
    "            test_loss = loss(params, (data[\"test_x\"], data[\"test_dx\"]), 0.0) / len(\n",
    "                data[\"test_x\"]\n",
    "            )\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "            if iteration >= 1000 and test_loss > 2.1:\n",
    "                # Only good seeds allowed!\n",
    "                break\n",
    "\n",
    "            if test_loss < best_loss:\n",
    "                best_loss = test_loss\n",
    "                best_params = copy(params)\n",
    "                bad_iterations = 0\n",
    "                offset += iteration\n",
    "                iteration = 0  # Keep going since this one is so good!\n",
    "\n",
    "            if jnp.isnan(test_loss).sum():\n",
    "                break\n",
    "\n",
    "            print(\n",
    "                f\"iteration={iteration}, train_loss={train_loss:.6f}, test_loss={test_loss:.6f}\"\n",
    "            )\n",
    "\n",
    "        bad_iterations += 1\n",
    "\n",
    "    import pickle as pkl\n",
    "\n",
    "    if best_loss < np.inf:\n",
    "        pkl.dump(\n",
    "            {\"params\": best_params, \"args\": args},\n",
    "            open(\"params_for_loss_{}_nupdates=1.pkl\".format(best_loss), \"wb\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(lnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(best_params, (data[\"test_x\"], data[\"test_dx\"]), 0.0) / len(data[\"test_x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "main2",
   "language": "python",
   "name": "main2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
